{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxLSzFTW1E1h",
        "outputId": "da77fdf6-e121-4eea-e258-f673c1afe595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install torch geometric -- for pyg\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2F3E2XB1H4m",
        "outputId": "76dc1b44-f0b2-4312-b5e8-7fa62656eb07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cuda.so\n",
            "  import torch_geometric.typing\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cuda.so\n",
            "  import torch_geometric.typing\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMwg9v4D1JEh",
        "outputId": "246730bd-3b91-4687-c59e-6fc361823c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the SkyNet Dataset\n",
        "\n",
        "We load our preprocessed flight-delay graphs using a custom `SkyNetDataset` class.\n",
        "Each graph represents a **6-hour block** of the US flight network, where:\n",
        "\n",
        "- **Nodes** = Airports (with geographic & weather features)\n",
        "- **Edges** = Individual flights (with scheduling & operational features)\n",
        "- **Labels** = Departure delays for each flight (regression target)\n",
        "\n",
        "We support two evaluation modes:\n",
        "\n",
        "- **Month Split**  \n",
        "  - Train on **Jan–Sep**  \n",
        "  - Test on **Oct–Dec**\n",
        "- **Random 80/20 Split**  \n",
        "  - Merge all individual graphs\n",
        "  - Mask 20% of the edges for test time.\n",
        "  - Train on the other 80% random edges.\n",
        "\n",
        "This ensures we evaluate **temporal generalization** rather than random splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fVaRc5r51KF4"
      },
      "outputs": [],
      "source": [
        "class SkyNetDataset(InMemoryDataset):\n",
        "    def __init__(self, root, mode='month_split', transform=None, pre_transform=None):\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.mode = mode\n",
        "\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
        "        data_list = [self.get(i) for i in range(len(self))]\n",
        "\n",
        "        new_list = []\n",
        "        for data in data_list:\n",
        "\n",
        "            # extract month/day from Python datetime\n",
        "            t = data.time\n",
        "            month = t.month\n",
        "            day = t.day\n",
        "\n",
        "            num_edges = data.edge_index.size(1)\n",
        "\n",
        "            # MONTH-SPLIT (whole graph train/test)\n",
        "            if self.mode == 'month_split':\n",
        "                if 1 <= month <= 9:\n",
        "                    train_mask = torch.ones(num_edges, dtype=torch.bool)\n",
        "                    test_mask  = torch.zeros(num_edges, dtype=torch.bool)\n",
        "                else:\n",
        "                    train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "                    test_mask  = torch.ones(num_edges, dtype=torch.bool)\n",
        "\n",
        "            # WEEK-SPLIT (edge-level)\n",
        "            elif self.mode == 'week_split':\n",
        "                # weeks 1–3 = days 1–21 → train\n",
        "                # week 4    = days ≥22   → test\n",
        "                train_mask = torch.tensor([day <= 21]*num_edges, dtype=torch.bool)\n",
        "                test_mask  = ~train_mask\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"mode must be 'month_split' or 'week_split'\")\n",
        "\n",
        "            data.train_edge_mask = train_mask\n",
        "            data.test_edge_mask  = test_mask\n",
        "            new_list.append(data)\n",
        "\n",
        "        self.data, self.slices = self.collate(new_list)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self): return []\n",
        "    @property\n",
        "    def processed_file_names(self): return ['flight_graphs.pt']\n",
        "    def process(self): pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merging Multiple Temporal Graphs\n",
        "\n",
        "Each 6-hour time block is stored as a separate graph.  \n",
        "To train a standard GCN effectively, we merge all training graphs into a single\n",
        "large graph and do the same for testing.\n",
        "\n",
        "Key details:\n",
        "\n",
        "- Node indices are shifted so graphs do not overlap.\n",
        "- We do **not** coalesce edges.  \n",
        "  Flights between the same airports in different months are distinct edges.\n",
        "- We concatenate:\n",
        "  - node features `x`\n",
        "  - edge indices `edge_index`\n",
        "  - edge features `edge_attr`\n",
        "  - labels `y`\n",
        "\n",
        "This produces one large graph for training and one for testing, which allows\n",
        "efficient message passing while maintaining strict temporal separation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jid7qUJ7jD9Q",
        "outputId": "d82a4843-9754-4446-a7aa-4dab8fa4d191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[116844, 9], edge_index=[2, 252484], edge_attr=[252484, 8], y=[252484], train_edge_mask=[252484], test_edge_mask=[252484], num_nodes=116844)\n",
            "Data(x=[39376, 9], edge_index=[2, 84292], edge_attr=[84292, 8], y=[84292], train_edge_mask=[84292], test_edge_mask=[84292], num_nodes=39376)\n"
          ]
        }
      ],
      "source": [
        "dataset = SkyNetDataset(\n",
        "    root='/content/drive/Shareddrives/CS_224W_Project/data/data/skynet_clean_graphs',\n",
        "    mode='month_split'\n",
        ")\n",
        "\n",
        "# Split graphs by month: Jan–Sep -> train, Oct–Dec -> test.\n",
        "# Each graph corresponds to a 6-hour window, so this enforces\n",
        "# a *temporal* train/test split rather than randomizing.\n",
        "train_graphs = [g for g in dataset if g.time.month <= 9]   # Jan–Sep\n",
        "test_graphs  = [g for g in dataset if g.time.month >= 10]  # Oct–Dec\n",
        "\n",
        "def merge_graphs(graph_list):\n",
        "    \"\"\"\n",
        "    Merge multiple PyG Data objects into a single large graph.\n",
        "\n",
        "    We do this so the GCN trains on one big connected component rather\n",
        "    than many tiny ones. Edge indices must be shifted so that nodes\n",
        "    from consecutive graphs don't overlap.\n",
        "    \"\"\"\n",
        "    x_list = []\n",
        "    ei_list = []\n",
        "    ea_list = []\n",
        "    y_list = []\n",
        "\n",
        "    cumulative_nodes = 0\n",
        "\n",
        "    for g in graph_list:\n",
        "        N = g.num_nodes\n",
        "\n",
        "        # append node features\n",
        "        x_list.append(g.x)\n",
        "\n",
        "        # shift edge indices by cumulative node count\n",
        "        ei_list.append(g.edge_index + cumulative_nodes)\n",
        "\n",
        "        # append edges + labels\n",
        "        ea_list.append(g.edge_attr)\n",
        "        y_list.append(g.y)\n",
        "\n",
        "        cumulative_nodes += N\n",
        "\n",
        "    # concatenate all\n",
        "    x = torch.cat(x_list, dim=0)\n",
        "    edge_index = torch.cat(ei_list, dim=1)\n",
        "    edge_attr  = torch.cat(ea_list, dim=0)\n",
        "    y          = torch.cat(y_list, dim=0)\n",
        "\n",
        "    # masks (all train for train graph, all test for test graph)\n",
        "    num_edges = edge_index.size(1)\n",
        "\n",
        "    data = Data(\n",
        "        x=x,\n",
        "        edge_index=edge_index,\n",
        "        edge_attr=edge_attr,\n",
        "        y=y,\n",
        "        train_edge_mask=torch.ones(num_edges, dtype=torch.bool),\n",
        "        test_edge_mask=torch.zeros(num_edges, dtype=torch.bool)\n",
        "    )\n",
        "    data.num_nodes = x.size(0)\n",
        "    return data\n",
        "\n",
        "#  Build final merged graphs\n",
        "train_graph = merge_graphs(train_graphs)\n",
        "test_graph  = merge_graphs(test_graphs)\n",
        "\n",
        "# For test_graph: invert masks\n",
        "test_graph.train_edge_mask[:] = False\n",
        "test_graph.test_edge_mask[:] = True\n",
        "\n",
        "print(train_graph)\n",
        "print(test_graph)\n",
        "\n",
        "train_loader = DataLoader([train_graph], batch_size=1)\n",
        "test_loader  = DataLoader([test_graph],  batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GCN Model for Edge-Level Delay Prediction\n",
        "\n",
        "We use a 3-layer Graph Convolutional Network to compute node embeddings.\n",
        "To produce predictions on edges (flights), we concatenate:\n",
        "\n",
        "- Source airport embedding\n",
        "- Destination airport embedding\n",
        "- Raw edge features (flight metadata)\n",
        "\n",
        "These are passed through an MLP to predict the delay for each flight.\n",
        "\n",
        "The model includes:\n",
        "- **BatchNorm** for training stability  \n",
        "- **Dropout** for regularization  \n",
        "- **Edge MLP** for final regression  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================================================\n",
        "# GCN model with BN + Dropout + Edge MLP (kept simple)\n",
        "# ===========================================================\n",
        "class EdgeRegressionGCN3(nn.Module):\n",
        "    def __init__(self, node_in, edge_in, hid=128, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.conv1 = GCNConv(node_in, hid)\n",
        "        self.conv2 = GCNConv(hid, hid)\n",
        "        self.conv3 = GCNConv(hid, hid)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(hid)\n",
        "        self.bn2 = nn.BatchNorm1d(hid)\n",
        "        self.bn3 = nn.BatchNorm1d(hid)\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(hid*2 + edge_in, hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hid, hid//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hid//2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        z = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
        "        z = F.dropout(z, p=self.dropout, training=self.training)\n",
        "\n",
        "        z = F.relu(self.bn2(self.conv2(z, edge_index)))\n",
        "        z = F.dropout(z, p=self.dropout, training=self.training)\n",
        "\n",
        "        z = F.relu(self.bn3(self.conv3(z, edge_index)))\n",
        "        z = F.dropout(z, p=self.dropout, training=self.training)\n",
        "\n",
        "        src, dst = edge_index\n",
        "        e = torch.cat([z[src], z[dst], edge_attr], dim=1)\n",
        "        return self.edge_mlp(e).squeeze(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Label Normalization\n",
        "\n",
        "Flight delays have a long-tailed distribution with large variance.  \n",
        "To stabilize training, we normalize all labels using the mean and standard\n",
        "deviation of the **training set only**.\n",
        "\n",
        "$$\n",
        "y_{\\text{norm}} = \\frac{y - \\mu_{\\text{train}}}{\\sigma_{\\text{train}}}\n",
        "$$\n",
        "\n",
        "Predictions on the test set are **denormalized** before computing final metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize labels using RAW y BEFORE merging\n",
        "all_train_y = torch.cat([g.y for g in train_graphs])  # raw, unmerged y\n",
        "y_mean = all_train_y.mean()\n",
        "y_std = all_train_y.std()\n",
        "\n",
        "train_graph.y = (train_graph.y - y_mean) / y_std\n",
        "test_graph.y  = (test_graph.y - y_mean) / y_std\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader([train_graph], batch_size=1)\n",
        "test_loader  = DataLoader([test_graph], batch_size=1)\n",
        "\n",
        "# Model + optimizer\n",
        "model = EdgeRegressionGCN3(\n",
        "    node_in=train_graph.x.size(1),\n",
        "    edge_in=train_graph.edge_attr.size(1),\n",
        "    hid=256,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Setup\n",
        "\n",
        "We train the model using mean squared error (MSE) over the edges marked as\n",
        "training edges. Since we merged all training graphs into a single graph,\n",
        "we can treat each mini-batch as the full graph (batch size = 1).\n",
        "\n",
        "Key settings:\n",
        "- Optimizer: **Adam (lr = 1e-3)**\n",
        "- Loss: **MSELoss**\n",
        "- Epochs: **70**\n",
        "- Single large-graph mini-batching for efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple training loop with loss tracking for plotting\n",
        "def train(model, loader, optimizer, criterion, epochs=40):\n",
        "    model.train()\n",
        "    loss_history = []   # <--- store losses here\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "            loss = criterion(pred[batch.train_edge_mask], batch.y[batch.train_edge_mask])\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        loss_history.append(total_loss)   # <--- record loss\n",
        "\n",
        "        print(f\"Epoch {epoch+1:03d} | Loss = {total_loss:.4f}\")\n",
        "\n",
        "    return model, loss_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "We evaluate the model on the merged test graph, using only edges marked as\n",
        "test edges.\n",
        "\n",
        "Metrics computed:\n",
        "- **MSE** (Mean Squared Error)\n",
        "- **RMSE** (Root MSE)\n",
        "- **MAE** (Mean Absolute Error)\n",
        "\n",
        "All metrics are reported in **raw delay minutes** after denormalization.\n",
        "This lets us compare the GCN directly to classical regression baselines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation (denormalize outputs)\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "\n",
        "    total_mse = 0\n",
        "    total_mae = 0\n",
        "    total_count = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        pred_norm = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "\n",
        "        # unnormalize\n",
        "        pred = pred_norm * y_std + y_mean\n",
        "        target = batch.y * y_std + y_mean\n",
        "\n",
        "        mask = batch.test_edge_mask\n",
        "        p = pred[mask]\n",
        "        t = target[mask]\n",
        "\n",
        "        total_mse += F.mse_loss(p, t, reduction='sum').item()\n",
        "        total_mae += F.l1_loss(p, t, reduction='sum').item()\n",
        "        total_count += t.numel()\n",
        "\n",
        "    return {\n",
        "        \"mse\": total_mse / total_count,\n",
        "        \"rmse\": (total_mse / total_count) ** 0.5,\n",
        "        \"mae\": total_mae / total_count\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO-auyv71QD8",
        "outputId": "dbb2d707-a773-4007-ba85-5e3681e89596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | Loss = 52.8789\n",
            "Epoch 002 | Loss = 58.0452\n",
            "Epoch 003 | Loss = 41.6119\n",
            "Epoch 004 | Loss = 17.6662\n",
            "Epoch 005 | Loss = 17.7958\n",
            "Epoch 006 | Loss = 23.8754\n",
            "Epoch 007 | Loss = 21.8595\n",
            "Epoch 008 | Loss = 14.9870\n",
            "Epoch 009 | Loss = 9.4105\n",
            "Epoch 010 | Loss = 7.6702\n",
            "Epoch 011 | Loss = 8.2292\n",
            "Epoch 012 | Loss = 9.0358\n",
            "Epoch 013 | Loss = 8.9410\n",
            "Epoch 014 | Loss = 7.7493\n",
            "Epoch 015 | Loss = 6.0141\n",
            "Epoch 016 | Loss = 4.4345\n",
            "Epoch 017 | Loss = 3.3201\n",
            "Epoch 018 | Loss = 2.7377\n",
            "Epoch 019 | Loss = 2.5856\n",
            "Epoch 020 | Loss = 2.6335\n",
            "Epoch 021 | Loss = 2.6719\n",
            "Epoch 022 | Loss = 2.6267\n",
            "Epoch 023 | Loss = 2.4345\n",
            "Epoch 024 | Loss = 2.1083\n",
            "Epoch 025 | Loss = 1.7308\n",
            "Epoch 026 | Loss = 1.4204\n",
            "Epoch 027 | Loss = 1.1678\n",
            "Epoch 028 | Loss = 0.9932\n",
            "Epoch 029 | Loss = 0.9079\n",
            "Epoch 030 | Loss = 0.8720\n",
            "Epoch 031 | Loss = 0.8667\n",
            "Epoch 032 | Loss = 0.8612\n",
            "Epoch 033 | Loss = 0.8517\n",
            "Epoch 034 | Loss = 0.8047\n",
            "Epoch 035 | Loss = 0.7612\n",
            "Epoch 036 | Loss = 0.6965\n",
            "Epoch 037 | Loss = 0.6263\n",
            "Epoch 038 | Loss = 0.5678\n",
            "Epoch 039 | Loss = 0.5074\n",
            "Epoch 040 | Loss = 0.4663\n",
            "Epoch 041 | Loss = 0.4367\n",
            "Epoch 042 | Loss = 0.4147\n",
            "Epoch 043 | Loss = 0.3979\n",
            "Epoch 044 | Loss = 0.3826\n",
            "Epoch 045 | Loss = 0.3656\n",
            "Epoch 046 | Loss = 0.3505\n",
            "Epoch 047 | Loss = 0.3341\n",
            "Epoch 048 | Loss = 0.3188\n",
            "Epoch 049 | Loss = 0.3045\n",
            "Epoch 050 | Loss = 0.2930\n",
            "Epoch 051 | Loss = 0.2791\n",
            "Epoch 052 | Loss = 0.2662\n",
            "Epoch 053 | Loss = 0.2556\n",
            "Epoch 054 | Loss = 0.2454\n",
            "Epoch 055 | Loss = 0.2330\n",
            "Epoch 056 | Loss = 0.2242\n",
            "Epoch 057 | Loss = 0.2137\n",
            "Epoch 058 | Loss = 0.2057\n",
            "Epoch 059 | Loss = 0.1962\n",
            "Epoch 060 | Loss = 0.1854\n",
            "Epoch 061 | Loss = 0.1797\n",
            "Epoch 062 | Loss = 0.1704\n",
            "Epoch 063 | Loss = 0.1625\n",
            "Epoch 064 | Loss = 0.1548\n",
            "Epoch 065 | Loss = 0.1489\n",
            "Epoch 066 | Loss = 0.1404\n",
            "Epoch 067 | Loss = 0.1356\n",
            "Epoch 068 | Loss = 0.1277\n",
            "Epoch 069 | Loss = 0.1216\n",
            "Epoch 070 | Loss = 0.1170\n",
            "\n",
            "=== FINAL TEST RESULTS ===\n",
            "RMSE: 12.689568109404194\n",
            "MAE : 12.541070030370616\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate\n",
        "trained_model, loss_history = train(model, train_loader, optimizer, criterion, epochs=70)\n",
        "results = evaluate(trained_model, test_loader)\n",
        "\n",
        "print(\"\\n=== FINAL TEST RESULTS ===\")\n",
        "print(\"RMSE:\", results[\"rmse\"])\n",
        "print(\"MAE :\", results[\"mae\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "2h5Mkd2l2Gne",
        "outputId": "f259f6c4-629d-4879-c994-fbc7a8867a8a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(loss_history, label=\"Training Loss\", linewidth=2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"GCN Training Loss Curve (Convergence)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SkyNetDataset: Random 80/20 Edge Split per Graph\n",
        "\n",
        "In this experiment, we do **not** split by time (months or weeks).  \n",
        "Instead, every graph (each 6-hour snapshot of the flight network) gets a **random 80/20 split of edges**:\n",
        "\n",
        "- **80% of edges** -> training  \n",
        "- **20% of edges** -> testing  \n",
        "\n",
        "This creates a purely structure-based learning setup, where the GNN must learn patterns in:\n",
        "- airport features,\n",
        "- weather,\n",
        "- flight attributes,\n",
        "- and connectivity structure,\n",
        "\n",
        "without relying on chronological information.\n",
        "\n",
        "This split tests whether the model can learn general flight-delay relationships independent of time.\n",
        "\n",
        "For each graph:\n",
        "1. Count the edges  \n",
        "2. Generate a random permutation  \n",
        "3. Assign 80% to training, 20% to testing  \n",
        "4. Store boolean masks inside the Data object  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JCXTW2I5L6p"
      },
      "outputs": [],
      "source": [
        "class SkyNetDataset(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "\n",
        "        # Load processed graphs from disk\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
        "\n",
        "        # Convert slices to list of Data objects\n",
        "        data_list = [self.get(i) for i in range(len(self))]\n",
        "\n",
        "        new_list = []\n",
        "        for data in data_list:\n",
        "            num_edges = data.edge_index.size(1)\n",
        "\n",
        "            # ---- RANDOM 80/20 SPLIT ----\n",
        "            perm = torch.randperm(num_edges)\n",
        "            split = int(0.8 * num_edges)\n",
        "\n",
        "            train_idx = perm[:split]\n",
        "            test_idx  = perm[split:]\n",
        "\n",
        "            train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "            test_mask  = torch.zeros(num_edges, dtype=torch.bool)\n",
        "            train_mask[train_idx] = True\n",
        "            test_mask[test_idx] = True\n",
        "\n",
        "            data.train_edge_mask = train_mask\n",
        "            data.test_edge_mask  = test_mask\n",
        "\n",
        "            new_list.append(data)\n",
        "\n",
        "        # Rebuild unified data + slices\n",
        "        self.data, self.slices = self.collate(new_list)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self): return []\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self): return ['flight_graphs.pt']\n",
        "\n",
        "    def process(self): pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merging All 12 Months into a Single Large Graph\n",
        "\n",
        "To allow the GNN to use information across the entire year, we merge all individual\n",
        "6-hour flight graphs into one unified graph:\n",
        "\n",
        "- All node features are concatenated  \n",
        "- All edges are concatenated  \n",
        "- Edge indices are shifted so node IDs remain unique  \n",
        "- Train/test masks from each graph are also concatenated  \n",
        "\n",
        "This produces **one huge graph** containing:\n",
        "- all airports for all months,\n",
        "- all flights for the entire year,\n",
        "- and a consistent global train/test split.\n",
        "\n",
        "This approach is similar to a transductive learning setup used in citation-network GNNs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = SkyNetDataset(\n",
        "    root='/content/drive/Shareddrives/CS_224W_Project/data/data/skynet_clean_graphs'\n",
        ")\n",
        "\n",
        "# Merging ALL graphs (12 months)\n",
        "all_graphs = [g for g in dataset]\n",
        "\n",
        "def merge_graphs(graph_list):\n",
        "    \"\"\"\n",
        "    Merge multiple PyG Data objects into a single large graph.\n",
        "\n",
        "    We do this so the GCN trains on one big connected component rather\n",
        "    than many tiny ones. Edge indices must be shifted so that nodes\n",
        "    from consecutive graphs don't overlap.\n",
        "    \"\"\"\n",
        "    x_list, ei_list, ea_list, y_list = [], [], [], []\n",
        "    mask_train_list, mask_test_list = [], []\n",
        "\n",
        "    cumulative_nodes = 0\n",
        "\n",
        "    for g in graph_list:\n",
        "        N = g.num_nodes\n",
        "\n",
        "        x_list.append(g.x)\n",
        "        ei_list.append(g.edge_index + cumulative_nodes)\n",
        "        ea_list.append(g.edge_attr)\n",
        "        y_list.append(g.y)\n",
        "\n",
        "        mask_train_list.append(g.train_edge_mask)\n",
        "        mask_test_list.append(g.test_edge_mask)\n",
        "\n",
        "        cumulative_nodes += N\n",
        "\n",
        "    x = torch.cat(x_list, dim=0)\n",
        "    edge_index = torch.cat(ei_list, dim=1)\n",
        "    edge_attr  = torch.cat(ea_list, dim=0)\n",
        "    y          = torch.cat(y_list, dim=0)\n",
        "\n",
        "    train_mask = torch.cat(mask_train_list, dim=0)\n",
        "    test_mask  = torch.cat(mask_test_list, dim=0)\n",
        "\n",
        "    data = Data(\n",
        "        x=x,\n",
        "        edge_index=edge_index,\n",
        "        edge_attr=edge_attr,\n",
        "        y=y,\n",
        "        train_edge_mask=train_mask,\n",
        "        test_edge_mask=test_mask\n",
        "    )\n",
        "    data.num_nodes = x.size(0)\n",
        "\n",
        "    return data\n",
        "\n",
        "big_graph = merge_graphs(all_graphs)\n",
        "print(big_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalizing Delay Labels\n",
        "\n",
        "The target variable `y` (departure delay in minutes) has a high natural variance\n",
        "(standard deviation ≈ 40 minutes).  \n",
        "To stabilize training, we normalize the labels **using only the training edges**:\n",
        "\n",
        "$$\n",
        "y_{\\text{norm}} = \\frac{y - \\mu_{\\text{train}}}{\\sigma_{\\text{train}}}\n",
        "$$\n",
        "\n",
        "This keeps test data completely unseen during normalization.\n",
        "\n",
        "During evaluation, we convert predictions back to real minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_train_y = big_graph.y[big_graph.train_edge_mask]\n",
        "y_mean = all_train_y.mean()\n",
        "y_std  = all_train_y.std()\n",
        "\n",
        "big_graph.y = (big_graph.y - y_mean) / y_std\n",
        "\n",
        "loader = DataLoader([big_graph], batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training on the Unified Graph\n",
        "\n",
        "We train the model on a single giant graph with full batching (batch size = 1).\n",
        "\n",
        "This means:\n",
        "- The GNN performs message passing over the entire US flight network (all months)\n",
        "- Training edges drive the gradient updates\n",
        "- Test edges remain masked and are only used during evaluation\n",
        "\n",
        "The loss curve reflects **normalized MSE**, not real delay minutes.  \n",
        "Real RMSE and MAE are computed after denormalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trained_model, loss_history = train(model, loader, optimizer, criterion, epochs=70)\n",
        "results = evaluate(trained_model, loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 26.22583012976106\n",
            "MAE: 19.738432638101827\n"
          ]
        }
      ],
      "source": [
        "print(\"RMSE:\", results[\"rmse\"])\n",
        "print(\"MAE:\", results[\"mae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(loss_history, label=\"Training Loss\", linewidth=2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"GCN Training Loss Curve (without weather data)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
