{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33aac456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/3rt9dzq92qq4mwb8qz5mh_cw0000gn/T/ipykernel_39157/103695542.py:2: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(KaggleDatasetAdapter.PANDAS, \"mahoora00135/flights\", file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:\n",
      "    id  year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "0   0  2013      1    1     517.0             515        2.0     830.0   \n",
      "1   1  2013      1    1     533.0             529        4.0     850.0   \n",
      "2   2  2013      1    1     542.0             540        2.0     923.0   \n",
      "3   3  2013      1    1     544.0             545       -1.0    1004.0   \n",
      "4   4  2013      1    1     554.0             600       -6.0     812.0   \n",
      "\n",
      "   sched_arr_time  arr_delay  ... flight  tailnum origin dest air_time  \\\n",
      "0             819       11.0  ...   1545   N14228    EWR  IAH    227.0   \n",
      "1             830       20.0  ...   1714   N24211    LGA  IAH    227.0   \n",
      "2             850       33.0  ...   1141   N619AA    JFK  MIA    160.0   \n",
      "3            1022      -18.0  ...    725   N804JB    JFK  BQN    183.0   \n",
      "4             837      -25.0  ...    461   N668DN    LGA  ATL    116.0   \n",
      "\n",
      "   distance  hour  minute            time_hour                    name  \n",
      "0      1400     5      15  2013-01-01 05:00:00   United Air Lines Inc.  \n",
      "1      1416     5      29  2013-01-01 05:00:00   United Air Lines Inc.  \n",
      "2      1089     5      40  2013-01-01 05:00:00  American Airlines Inc.  \n",
      "3      1576     5      45  2013-01-01 05:00:00         JetBlue Airways  \n",
      "4       762     6       0  2013-01-01 06:00:00    Delta Air Lines Inc.  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"flights.csv\"\n",
    "df = kagglehub.load_dataset(KaggleDatasetAdapter.PANDAS, \"mahoora00135/flights\", file_path)\n",
    "\n",
    "print(\"First 5 records:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c73c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 11.105526164238547\n",
      "RMSE: 15.497924409921017\n"
     ]
    }
   ],
   "source": [
    "# choose target\n",
    "target = \"arr_delay\"\n",
    "\n",
    "# drop rows with missing target\n",
    "df2 = df[df[target].notna()].copy()\n",
    "\n",
    "# split features/labels\n",
    "X = df2.drop(columns=[target])\n",
    "y = df2[target]\n",
    "\n",
    "#  categorical + numeric columns\n",
    "categorical_cols = ['carrier', 'tailnum', 'origin', 'dest', 'time_hour', 'name']\n",
    "numeric_cols = ['id', 'year', 'month', 'day', 'dep_time', 'sched_dep_time', \n",
    "                'dep_delay', 'arr_time', 'sched_arr_time', 'flight', \n",
    "                'air_time', 'distance', 'hour', 'minute']\n",
    "\n",
    "# build preprocessing\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# full model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"ridge\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "rmse = root_mean_squared_error(y_test, pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968acf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 11.09571481789264\n",
      "RMSE: 15.484329056442682\n"
     ]
    }
   ],
   "source": [
    "# choose target\n",
    "target = \"arr_delay\"\n",
    "\n",
    "# drop rows with missing target\n",
    "df2 = df[df[target].notna()].copy()\n",
    "\n",
    "# split features/labels\n",
    "X = df2.drop(columns=[target])\n",
    "y = df2[target]\n",
    "\n",
    "# categorical + numeric columns\n",
    "categorical_cols = ['carrier', 'tailnum', 'origin', 'dest', 'time_hour', 'name']\n",
    "numeric_cols = ['id', 'year', 'month', 'day', 'dep_time', 'sched_dep_time', \n",
    "                'dep_delay', 'arr_time', 'sched_arr_time', 'flight', \n",
    "                'air_time', 'distance', 'hour', 'minute']\n",
    "\n",
    "# build preprocessing\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# full model pipeline\n",
    "model = Pipeline([(\"preprocess\", preprocess),\n",
    "        (\"model\", LinearRegression())])\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "rmse = root_mean_squared_error(y_test, pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a7643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
